{"titanic": "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: \u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc).\n\nIn this competition, you\u2019ll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled train.csv and the other is titled test.csv.\n\nTrain.csv will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the \u201cground truth\u201d.\n\nThe test.csv dataset contains similar information but does not disclose the \u201cground truth\u201d for each passenger. It\u2019s your job to predict these outcomes.\n\nUsing the patterns you find in the train.csv data, predict whether the other 418 passengers on board (found in test.csv) survived.\n\nCheck out the \u201cData\u201d tab to explore the datasets even further. Once you feel you\u2019ve created a competitive model, submit it to Kaggle to see where your model stands on our leaderboard against other Kagglers.\n    \n    Dataset Description\nOverview\nThe data has been split into two groups:\n\ntraining set (train.csv)\ntest set (test.csv)\nThe training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the \u201cground truth\u201d) for each passenger. Your model will be based on \u201cfeatures\u201d like passengers\u2019 gender and class. You can also use feature engineering to create new features.\n\nThe test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n\nWe also include gender_submission.csv, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.\n    ", "credit-g": "German Credit dataset\nThis dataset classifies people described by a set of attributes as good or bad credit risks.\n\nThis dataset comes with a cost matrix:\n\nGood  Bad (predicted)  \nGood   0    1   (actual)  \nBad    5    0  \nIt is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).\n\nAttribute description\nStatus of existing checking account, in Deutsche Mark.\nDuration in months\nCredit history (credits taken, paid back duly, delays, critical accounts)\nPurpose of the credit (car, television,...)\nCredit amount\nStatus of savings account/bonds, in Deutsche Mark.\nPresent employment, in number of years.\nInstallment rate in percentage of disposable income\nPersonal status (married, single,...) and sex\nOther debtors / guarantors\nPresent residence since X years\nProperty (e.g. real estate)\nAge in years\nOther installment plans (banks, stores)\nHousing (rent, own,...)\nNumber of existing credits at this bank\nJob\nNumber of people being liable to provide maintenance for\nTelephone (yes,no)\nForeign worker (yes,no)\n    ", "playground-series-s3e23": "Welcome to the 2023 edition of Kaggle's Playground Series!\nThank you to everyone who participated in and contributed to Season 3 Playground Series so far!\n\nWith the same goal to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science, we will continue launching the Tabular Tuesday in October every Tuesday 00:00 UTC, with each competition running for 3 weeks. Again, these will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nYour Goal: Predict defects in C programs given various various attributes about the code.\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Software Defect Dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; defects is the binary target, which is treated as a boolean (False=0, True=1)\ntest.csv - the test dataset; your objective is to predict the probability of positive defects (i.e., defects=True)\nsample_submission.csv - a sample submission file in the correct format\n", "playground-series-s4e3": "Welcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting an approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal: Predict the probability of various defects on steel plates. Good luck!\n\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Steel Plates Faults dataset from UCI. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; there are 7 binary targets: Pastry, Z_Scratch, K_Scatch, Stains, Dirtiness, Bumps, Other_Faults\ntest.csv - the test dataset; your objective is to predict the probability of each of the 7 binary targets\nsample_submission.csv - a sample submission file in the correct format\n", "steel-dataset": "Content\nThis company produces several types of coils, steel plates, and iron plates. The information on electricity consumption is held in a cloud-based system. The information on energy consumption of the industry is stored on the website of the Korea Electric Power Corporation (pccs.kepco.go.kr), and the perspectives on daily, monthly, and annual data are calculated and shown.\n\nAttribute Information:\nDate Continuous-time data taken on the first of the month\nUsage_kWh Industry Energy Consumption Continuous kWh\nLagging Current reactive power Continuous kVarh\nLeading Current reactive power Continuous kVarh\nCO2 Continuous ppm\nNSM Number of Seconds from midnight Continuous S\nWeek status Categorical (Weekend (0) or a Weekday(1))\nDay of week Categorical Sunday, Monday : Saturday\nLoad Type Categorical Light Load, Medium Load, Maximum Load\n\nAcknowledgements\nThis dataset is sourced from the UCI Machine Learning Repository\n", "health_insurance": "Our client is an Insurance company that has provided Health Insurance to its customers now they need your help in building a model to predict whether the policyholders (customers) from past year will also be interested in Vehicle Insurance provided by the company.\n\nAn insurance policy is an arrangement by which a company undertakes to provide a guarantee of compensation for specified loss, damage, illness, or death in return for the payment of a specified premium. A premium is a sum of money that the customer needs to pay regularly to an insurance company for this guarantee.\n\nFor example, you may pay a premium of Rs. 5000 each year for a health insurance cover of Rs. 200,000/- so that if, God forbid, you fall ill and need to be hospitalised in that year, the insurance provider company will bear the cost of hospitalisation etc. for upto Rs. 200,000. Now if you are wondering how can company bear such high hospitalisation cost when it charges a premium of only Rs. 5000/-, that is where the concept of probabilities comes in picture. For example, like you, there may be 100 customers who would be paying a premium of Rs. 5000 every year, but only a few of them (say 2-3) would get hospitalised that year and not everyone. This way everyone shares the risk of everyone else.\n\nJust like medical insurance, there is vehicle insurance where every year customer needs to pay a premium of certain amount to insurance provider company so that in case of unfortunate accident by the vehicle, the insurance provider company will provide a compensation (called \u2018sum assured\u2019) to the customer.\n\nBuilding a model to predict whether a customer would be interested in Vehicle Insurance is extremely helpful for the company because it can then accordingly plan its communication strategy to reach out to those customers and optimise its business model and revenue.\n\nNow, in order to predict, whether the customer would be interested in Vehicle insurance, you have information about demographics (gender, age, region code type), Vehicles (Vehicle Age, Damage), Policy (Premium, sourcing channel) etc.\n\nData Description\nTrain Data\nVariable\tDefinition\nid\tUnique ID for the customer\nGender\tGender of the customer\nAge\tAge of the customer\nDriving_License\t0 : Customer does not have DL, 1 : Customer already has DL\nRegion_Code\tUnique code for the region of the customer\nPreviously_Insured\t1 : Customer already has Vehicle Insurance, 0 : Customer doesn't have Vehicle Insurance\nVehicle_Age\tAge of the Vehicle\nVehicle_Damage\t1 : Customer got his/her vehicle damaged in the past. 0 : Customer didn't get his/her vehicle damaged in the past.\nAnnual_Premium\tThe amount customer needs to pay as premium in the year\nPolicy_Sales_Channel\tAnonymized Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc.\nVintage\tNumber of Days, Customer has been associated with the company\nResponse\t1 : Customer is interested, 0 : Customer is not interested\nTest Data\nVariable\tDefinition\nid\tUnique ID for the customer\nGender\tGender of the customer\nAge\tAge of the customer\nDriving_License\t0 : Customer does not have DL, 1 : Customer already has DL\nRegion_Code\tUnique code for the region of the customer\nPreviously_Insured\t1 : Customer already has Vehicle Insurance, 0 : Customer doesn't have Vehicle Insurance\nVehicle_Age\tAge of the Vehicle\nVehicle_Damage\t1 : Customer got his/her vehicle damaged in the past. 0 : Customer didn't get his/her vehicle damaged in the past.\nAnnual_Premium\tThe amount customer needs to pay as premium in the year\nPolicy_Sales_Channel\tAnonymised Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc.\nVintage\tNumber of Days, Customer has been associated with the company\nSubmission\nVariable\tDefinition\nid\tUnique ID for the customer\nResponse\t1 : Customer is interested, 0 : Customer is not interested\nEvaluation Metric\nThe evaluation metric for this hackathon is ROC_AUC score.\n\nPublic and Private split\nThe public leaderboard is based on 40% of test data, while final rank would be decided on remaining 60% of test data (which is private leaderboard)\n\nGuidelines for Final Submission\nPlease ensure that your final submission includes the following:\n\nSolution file containing the predicted response of the customer (Probability of response 1)\nCode file for reproducing the submission, note that it is mandatory to submit your code for a valid final submission\n"}